{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf30db0-383f-4bb9-a903-c0eb4b932d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "명령 구문이 올바르지 않습니다.\n",
      "'cp'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/aiffel/fnguide/data\n",
    "!cp -r ~/data/* ~/aiffel/fnguide/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e78d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1eaaae",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/aiffel/aiffel/fnguide/data/sub_upbit_eth_min_tick.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m DATA_PATH = \u001b[33m'\u001b[39m\u001b[33m/aiffel/aiffel/fnguide/data/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 데이터 불러오기\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m modify_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msub_upbit_eth_min_tick.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 불러온 데이터 시각화하기\u001b[39;00m\n\u001b[32m      8\u001b[39m modify_data.loc[\u001b[33m'\u001b[39m\u001b[33m2017-11-01\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33m2017-12-31\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m'\u001b[39m].plot()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/aiffel/aiffel/fnguide/data/sub_upbit_eth_min_tick.csv'"
     ]
    }
   ],
   "source": [
    "# 데이터 경로\n",
    "DATA_PATH = '/aiffel/aiffel/fnguide/data/'\n",
    "\n",
    "# 데이터 불러오기\n",
    "modify_data = pd.read_csv(os.path.join(DATA_PATH, 'sub_upbit_eth_min_tick.csv'), index_col=0, parse_dates=True)\n",
    "\n",
    "# 불러온 데이터 시각화하기\n",
    "modify_data.loc['2017-11-01':'2017-12-31','close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56796f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Change Direction 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3421165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# window 지정\n",
    "window = 5 # 앞서 사용한 window의 값은 10입니다.\n",
    "\n",
    "# momentum_signal 만들기\n",
    "momentum_signal = np.sign(np.sign(modify_data['close'] - modify_data['close'].shift(window)) + 1) # modify_data['close'].shift(window)활용\n",
    "\n",
    "# s_momentum_signal 만들기\n",
    "s_momentum_signal = pd.Series(momentum_signal, index=modify_data.index) # 데이터 활용을 위해 pd.Series를 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# 기존 데이터 만들기\n",
    "sub_data = modify_data.loc['2017-11-21', 'close'] # loc를 활용하여 2017-11-21부터 close(종가)까지 가져오기\n",
    "\n",
    "# 수식 적용된 데이터 만들기\n",
    "c_sig =s_momentum_signal.loc['2017-11-21'] # loc를 활용하여 2017-11-21의 시간대별 값을 가져오기\n",
    "\n",
    "# 두 데이터의 비교를 위한 색상 바꾸기\n",
    "c_sig['color'] =  np.where(c_sig == 1, 'red', 'blue') # np.where 사용\n",
    "\n",
    "# 시각화하기\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(sub_data.index, sub_data, c=c_sig['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ② Using Moving Average 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# momentum_signal \n",
    "momentum_signal = np.sign(np.sign(modify_data['close'] - modify_data['close'].rolling(window).mean()) + 1) # modify_data['close'].rolling(window).mean() 활용\n",
    "\n",
    "# s_momentum_signal\n",
    "s_momentum_signal = pd.Series(momentum_signal, index=modify_data.index) # pd.Series로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ad874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# 기존 데이터 만들기\n",
    "sub_data = modify_data.loc['2017-11-21', 'close']\n",
    "\n",
    "# 수식 적용된 데이터 만들기\n",
    "c_sig = s_momentum_signal.loc['2017-11-21']\n",
    "\n",
    "# 두 데이터의 비교를 위한 색상 바꾸기\n",
    "c_sig['color'] = np.where(c_sig == 1, 'red', 'blue')\n",
    "\n",
    "# 시각화하기\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(sub_data.index, sub_data, c=c_sig['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2609c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Min-Max 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06a0ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# Local min / max 를 추출하기 위한 함수\n",
    "def get_local_min_max(close, wait=3):\n",
    "    min_value = close.iloc[0]\n",
    "    max_value = close.iloc[0] # ①\n",
    "    n_cnt_min, n_cnt_max = 0, 0\n",
    "    \n",
    "    mins, maxes = [], []\n",
    "    min_idxes, max_idxes = [], []\n",
    "    b_min_update, b_max_update = False, False\n",
    "    \n",
    "    for idx, val in zip(close.index[1:], close.values[1:]):\n",
    "        if val < min_value:\n",
    "            min_value = val\n",
    "            mins.append(min_value)\n",
    "            min_idxes.append(idx)\n",
    "            n_cnt_min = 0\n",
    "            b_min_update = True\n",
    "        if val > max_value:\n",
    "            max_value = val # ②\n",
    "            maxes.append(max_value)  # ③\n",
    "            max_idxes.append(idx)\n",
    "            n_cnt_max = 0\n",
    "            b_max_update = True # ④\n",
    "        \n",
    "        if not b_max_update:\n",
    "            b_min_update = False\n",
    "            n_cnt_min += 1\n",
    "            if n_cnt_min >= wait:\n",
    "                max_value = min_value\n",
    "                n_cnt_min = 0\n",
    "    \n",
    "        if not b_min_update:\n",
    "            b_max_update = False # ⑤\n",
    "            n_cnt_max += 1 # ⑥\n",
    "            if n_cnt_max >= wait:\n",
    "                min_value = max_value # ⑦\n",
    "                n_cnt_max = 0\n",
    "               \n",
    "    return pd.DataFrame.from_dict({'min_time': min_idxes, 'local_min': mins}), pd.DataFrame.from_dict({'max_time': max_idxes, 'local_max': maxes}) # ⑧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c2a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_local_min_max 함수를 사용하면 return 값이 2개가 나오게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afdb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local mins, maxes를 확인\n",
    "mins, maxes = get_local_min_max(sub_data, wait=3)\n",
    "\n",
    "# mins, maxes 확인 \n",
    "print(mins)\n",
    "print('--'*20)\n",
    "print(maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fef959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# subplots 및 plot 생성\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.plot(sub_data, 'c')\n",
    "\n",
    "# min_time, local_min을 활용한 scatter plot 생성\n",
    "ax.scatter(mins.min_time, mins.local_min, c='blue')\n",
    "\n",
    "# maxes_time, local_max를 활용한 scatter plot 생성\n",
    "ax.scatter(maxes.max_time, maxes.local_max, c='red')\n",
    "\n",
    "# y축 설정\n",
    "ax.set_ylim([sub_data.min() * 0.99, sub_data.max()  * 1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d854512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend Scanning 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e004e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_val_lin_r(close):\n",
    "    import statsmodels.api as sml\n",
    "    \n",
    "    # t-value from a linear trend\n",
    "    x = np.ones((close.shape[0], 2))\n",
    "    x[:, 1] = np.arange(close.shape[0])\n",
    "    ols = sml.OLS(close, x).fit() \n",
    "    return ols.tvalues[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_forward_window = 60\n",
    "min_sample_length = 5\n",
    "step = 1\n",
    "t1_array = []\n",
    "t_values_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# 이 코드 블럭은 실행에 20-30분정도가 소요될 수 있습니다.\n",
    "\n",
    "molecule = modify_data['2017-11-01':'2017-11-30'].index\n",
    "label = pd.DataFrame(index=molecule, columns=['t1', 't_val', 'bin'])\n",
    "tmp_out = []\n",
    "\n",
    "for ind in tqdm(molecule):\n",
    "    subset = modify_data.loc[ind:, 'close'].iloc[:look_forward_window]  # 전방 탐색을 위한 샘플 추출\n",
    "    if look_forward_window > subset.shape[0]:\n",
    "        continue\n",
    "    \n",
    "    tmp_subset = pd.Series(index=subset.index[min_sample_length-1:subset.shape[0]-1])\n",
    "    tval = []\n",
    "\n",
    "    # 회귀분석을 통해 t 통계량값을 이용하여 추세 추정\n",
    "    for forward_window in np.arange(min_sample_length, subset.shape[0]):\n",
    "        df = subset.iloc[:forward_window]\n",
    "        tval.append(t_val_lin_r(df.values))  # t-value 사용\n",
    "    \n",
    "    tmp_subset.loc[tmp_subset.index] = np.array(tval)\n",
    "    idx_max = tmp_subset.replace([-np.inf, np.inf, np.nan], 0).abs().idxmax()\n",
    "    tmp_t_val = tmp_subset[idx_max]\n",
    "    tmp_out.append([tmp_subset.index[-1], tmp_t_val, np.sign(tmp_t_val)])\n",
    "\n",
    "label.loc[molecule] = np.array(tmp_out)  # prevent leakage\n",
    "\n",
    "label['t1'] = pd.to_datetime(label['t1'])\n",
    "label['bin'] = pd.to_numeric(label['bin'], downcast='signed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eea706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "sub_data = modify_data.loc['2017-11-21', 'close']\n",
    "c_sig = label['bin'].loc['2017-11-21']\n",
    "c_sig['color'] = np.where(c_sig == 1, 'red', 'blue')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.scatter(sub_data.index, sub_data.values, c=c_sig['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ta==0.9.0\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbeec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ta\n",
    "\n",
    "import sys\n",
    "sys.path.append('/aiffel/aiffel/fnguide/data/')\n",
    "from libs.feature_importance import importance as imp\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, RFECV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc6fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "DATA_PATH = '/aiffel/aiffel/fnguide/data/'\n",
    "anno_file_name = os.path.join(DATA_PATH, 'sub_upbit_eth_min_tick_label.pkl')\n",
    "target_file_name = os.path.join(DATA_PATH, 'sub_upbit_eth_min_tick.csv')\n",
    "\n",
    "# 데이터 불러오기\n",
    "df_modify_data = pd.read_csv(target_file_name, index_col=0, parse_dates=True)\n",
    "df_label_data = pd.read_pickle(anno_file_name)\n",
    "df_sub_modify_data = df_modify_data.loc[df_label_data.index]\n",
    "\n",
    "# 학습 시간 단축을 위해 여기선 편의상 1000개의 데이터만 가져옵니다.\n",
    "df_sub_modify_data = df_sub_modify_data.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbbdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical Index 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf02ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기술적 지표를 적용합니다.\n",
    "\n",
    "mt = 1\n",
    "fillna = False\n",
    "df_ = df_sub_modify_data.copy()\n",
    "open, high, low, close, volume = 'open', 'high', 'low', 'close', 'volume'\n",
    "cols = [open, high, low, close, volume]\n",
    "\n",
    "## Volume Index\n",
    "# Chaikin Money Flow\n",
    "df_[\"volume_cmf\"] = ta.volume.ChaikinMoneyFlowIndicator(\n",
    "                        high=df_[high], low=df_[low], close=df_[close], volume=df_[volume], window=20*mt, fillna=fillna\n",
    "                    ).chaikin_money_flow()\n",
    "# Force Index\n",
    "df_[\"volume_fi\"] = ta.volume.ForceIndexIndicator(\n",
    "                        close=df_[close], volume=df_[volume], window=15*mt, fillna=fillna\n",
    "                    ).force_index()\n",
    "# Money Flow Indicator\n",
    "df_[\"volume_mfi\"] = ta.volume.MFIIndicator(\n",
    "                        high=df_[high],\n",
    "                        low=df_[low],\n",
    "                        close=df_[close],\n",
    "                        volume=df_[volume],\n",
    "                        window=15*mt,\n",
    "                        fillna=fillna,\n",
    "                    ).money_flow_index()\n",
    "# Ease of Movement\n",
    "df_[\"volume_sma_em\"] = ta.volume.EaseOfMovementIndicator(\n",
    "                            high=df_[high], low=df_[low], volume=df_[volume], window=15*mt, fillna=fillna\n",
    "                        ).sma_ease_of_movement()\n",
    "\n",
    "# Volume Price Trend\n",
    "df_[\"volume_vpt\"] = ta.volume.VolumePriceTrendIndicator(\n",
    "                        close=df_[close], volume=df_[volume], fillna=fillna\n",
    "                    ).volume_price_trend()\n",
    "\n",
    "## volatility index\n",
    "# Average True Range\n",
    "df_[\"volatility_atr\"] = ta.volatility.AverageTrueRange(\n",
    "                            close=df_[close], high=df_[high], low=df_[low], window=10*mt, fillna=fillna\n",
    "                        ).average_true_range()\n",
    "\n",
    "# Ulcer Index\n",
    "df_[\"volatility_ui\"] = ta.volatility.UlcerIndex(\n",
    "                            close=df_[close], window=15*mt, fillna=fillna\n",
    "                        ).ulcer_index()\n",
    "\n",
    "## trend index\n",
    "# MACD\n",
    "df_[\"trend_macd_diff\"] = ta.trend.MACD(\n",
    "                            close=df_[close], window_slow=25*mt, window_fast=10*mt, window_sign=9, fillna=fillna\n",
    "                        ).macd_diff()\n",
    "\n",
    "# Average Directional Movement Index (ADX)\n",
    "df_[\"trend_adx\"] = ta.trend.ADXIndicator(\n",
    "                        high=df_[high], low=df_[low], close=df_[close], window=15*mt, fillna=fillna\n",
    "                    ).adx()\n",
    "\n",
    "# TRIX Indicator\n",
    "df_[\"trend_trix\"] = ta.trend.TRIXIndicator(\n",
    "                        close=df_[close], window=15*mt, fillna=fillna\n",
    "                    ).trix()\n",
    "\n",
    "# Mass Index\n",
    "df_[\"trend_mass_index\"] = ta.trend.MassIndex(\n",
    "                            high=df_[high], low=df_[low], window_fast=10*mt, window_slow=25*mt, fillna=fillna\n",
    "                        ).mass_index()\n",
    "\n",
    "# DPO Indicator\n",
    "df_[\"trend_dpo\"] = ta.trend.DPOIndicator(\n",
    "                        close=df_[close], window=20*mt, fillna=fillna\n",
    "                    ).dpo()\n",
    "\n",
    "# Aroon Indicator\n",
    "df_[\"trend_aroon_ind\"] = ta.trend.AroonIndicator(close=df_[close], window=20, fillna=fillna).aroon_indicator()\n",
    "\n",
    "## momentum index\n",
    "# Relative Strength Index (RSI)\n",
    "df_[\"momentum_rsi\"] = ta.momentum.RSIIndicator(close=df_[close], window=15*mt, fillna=fillna).rsi()\n",
    "\n",
    "# Williams R Indicator\n",
    "df_[\"momentum_wr\"] = ta.momentum.WilliamsRIndicator(\n",
    "                        high=df_[high], low=df_[low], close=df_[close], lbp=15*mt, fillna=fillna\n",
    "                    ).williams_r()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46251268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수익률 / 변동성 지표를 적용합니다.\n",
    "windows_mom = [5, 10, 20]\n",
    "windows_std = [30]\n",
    "\n",
    "for i in windows_mom:\n",
    "    df_[f'vol_change_{i}'] = df_.volume.pct_change(i).round(6)\n",
    "    df_[f'ret_{i}'] = df_.close.pct_change(i).round(6)\n",
    "\n",
    "for i in windows_std:\n",
    "    df_[f'std_{i}'] = df_.close.rolling(i).std()\n",
    "    df_[f'vol_std_{i}'] = df_.volume.rolling(i).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969045fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "df_tmp_data = df_.join(df_label_data).dropna()\n",
    "\n",
    "# X, y 데이터셋 만들기\n",
    "X = df_tmp_data.iloc[:, 5:-1] \n",
    "y = df_tmp_data.iloc[:, -1] # iloc[:, -1] 사용\n",
    "\n",
    "# StandardScaler 적용\n",
    "sc = StandardScaler()\n",
    "\n",
    "# fit_transform 사용\n",
    "X_sc = sc.fit_transform(X)\n",
    "\n",
    "# DataFrame 변환\n",
    "X_sc = pd.DataFrame(X_sc, index=X.index, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# RandomForest 모델 적용\n",
    "rfc = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# RandomForest fit 하기\n",
    "rfc.fit(X_sc, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Feature Selection methods 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDI, Mean Decrease Impurity \n",
    "feat_imp = imp.mean_decrease_impurity(rfc, X.columns)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbaec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDA, Mean Decrease Accuracy\n",
    "svc_rbf = SVC(kernel='rbf', probability=True) # Tree 및 Support Vector Machine 외에 다른 분류기(classifier)를 사용해봅시다.\n",
    "cv = KFold(n_splits=3) # n_splits을 변경해봅시다.\n",
    "feat_imp_mda = imp.mean_decrease_accuracy(svc_rbf, X_sc, y, cv_gen=cv)\n",
    "feat_imp_mda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_feature_importance 함수 만들기\n",
    "def plot_feature_importance(importance_df, save_fig=False, output_path=None):\n",
    "    # Plot mean imp bars with std\n",
    "    plt.figure(figsize=(10, importance_df.shape[0] / 5))\n",
    "    importance_df.sort_values('mean', ascending=True, inplace=True)\n",
    "    importance_df['mean'].plot(kind='barh', color='b', alpha=0.25, xerr=importance_df['std'], error_kw={'ecolor': 'r'})\n",
    "    if save_fig:\n",
    "        plt.savefig(output_path) \n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a71c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# feat_imp 확인\n",
    "plot_feature_importance(feat_imp)\n",
    "\n",
    "# feat_imp_mda 확인\n",
    "plot_feature_importance(feat_imp_mda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987113c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE CV, Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3af47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# RFE CV, Recursive Feature Elimination\n",
    "svc_rbf = SVC(kernel='linear', probability=True) \n",
    "rfe_cv = RFECV(svc_rbf, cv=cv) # RFECV\n",
    "rfe_fitted = rfe_cv.fit(X_sc, y) # fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a710ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 피쳐 확인하기\n",
    "\n",
    "rfe_df = pd.DataFrame([rfe_fitted.support_, rfe_fitted.ranking_], columns=X_sc.columns).T.rename(columns={0:\"Optimal_Features\", 1:\"Ranking\"})\n",
    "rfe_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dde284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFS, Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFS, Sequential Feature Selection\n",
    "\n",
    "n = 2\n",
    "sfs_forward = SequentialFeatureSelector(svc_rbf, n_features_to_select=n, direction='forward')\n",
    "sfs_fitted = sfs_forward.fit(X_sc, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8386cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 피쳐 확인하기\n",
    "\n",
    "sfs_rank = sfs_fitted.get_support()\n",
    "sfs_df = pd.DataFrame(sfs_rank, index=X_sc.columns, columns={\"Optimal_Features\"})\n",
    "\n",
    "sfs_df [sfs_df [\"Optimal_Features\"]==True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP, Shapley Additive explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# SHAP, Shapley Additive explanations\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(rfc)\n",
    "shap_value = explainer.shap_values(X_sc)\n",
    "\n",
    "# shap_value, X_sc 사용 shap.summary_plot 그리기\n",
    "shap.summary_plot(shap_value, X_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d005467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버전간의 문제가 발생함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4590c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "sys.path.append('/aiffel/aiffel/fnguide/data/')\n",
    "from libs.mlutil.pkfold import PKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e803cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정 및 pickle 파일 불러오기\n",
    "DATA_PATH = '/aiffel/aiffel/fnguide/data/'\n",
    "data_file_name = os.path.join(DATA_PATH, 'sub_upbit_eth_min_feature_labels.pkl')\n",
    "\n",
    "\n",
    "# 여기서부터 모델에 적용하기 위한 데이터 정제화를 시작합니다.\n",
    "df_data = pd.read_pickle(data_file_name)\n",
    "df_data['t_value'] = df_data['t_value'].apply(lambda x: x if x == 1 else 0)\n",
    "df_data['t_value'].value_counts()\n",
    "\n",
    "# 데이터셋 비율 나누기\n",
    "train_ratio, test_ratio = 0.7, 0.2\n",
    "n_train = int(np.round(len(df_data) * train_ratio))\n",
    "n_test = int(np.round(len(df_data) * test_ratio))\n",
    "\n",
    "X, y = df_data.iloc[:, 5:-1], df_data.iloc[:, -1]\n",
    "\n",
    "# standardzation\n",
    "sc = StandardScaler()\n",
    "X_sc = sc.fit_transform(X)\n",
    "\n",
    "# 데이터셋 분리\n",
    "train_x, test_x, train_y, test_y = X_sc[:n_train, :], X_sc[-n_test:, :], y.iloc[:n_train], y.iloc[-n_test:]\n",
    "\n",
    "train_x = pd.DataFrame(train_x, index=train_y.index, columns=X.columns)\n",
    "train_y = pd.Series(train_y, index=train_y.index)\n",
    "test_x = pd.DataFrame(test_x, index=test_y.index, columns=X.columns)\n",
    "test_y = pd.Series(test_y, index=test_y.index)\n",
    "\n",
    "# 학습 시간 단축을 위해 여기선 편의상 1000개의 데이터만 가져옵니다.\n",
    "train_x = train_x[:1000] # 데이터셋을 증가 혹은 감소시켜 결과를 비교해봅시다.\n",
    "train_y = train_y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purged K-fold for Cross-Validation적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "n_cv =4 # 앞에서 지정한 값은 4입니다. 과적합을 제한하기 위해서 5회 정도가 적당한 경험\n",
    "t1 = pd.Series(train_y.index.values, index=train_y.index)\n",
    "\n",
    "# purged K-Fold \n",
    "cv = PKFold(n_cv, t1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b535c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f0fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridsearchCV에서 사용할 파라미터 설정합니다. 파라미터값을 바꿔보세요\n",
    "bc_params = {'n_estimators': [5, 10, 20],\n",
    "             'max_features': [0.5, 0.7],\n",
    "             'base_estimator__max_depth': [3,5,10,20],\n",
    "             'base_estimator__max_features': [None, 'auto'],\n",
    "             'base_estimator__min_samples_leaf': [3, 5, 10],\n",
    "             'bootstrap_features': [False, True]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba0d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest 사용\n",
    "rfc = RandomForestClassifier(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# Bagging 적용\n",
    "bag_rfc = BaggingClassifier(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# GridSearchCV 적용\n",
    "gs_rfc = GridSearchCV(bag_rfc, bc_params, cv=cv, n_jobs= -1 , verbose=1)\n",
    "\n",
    "#병렬데이터 철리 문제가 발생함, 이를 해결하기 위해 n_jobs= -1 를 1로 조절 함. 때문에 연산 속도가 확연히 낮아짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dc2b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "gs_rfc.fit(train_x, train_y)\n",
    "\n",
    "# best estimator \n",
    "gs_rfc_best = gs_rfc.best_estimator_\n",
    "gs_rfc_best.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15175101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 확인\n",
    "pred_y = gs_rfc_best.predict(test_x)\n",
    "prob_y = gs_rfc_best.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e33e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# test_y, pred_y를 활용한 지표 적용\n",
    "confusion = confusion_matrix(test_y, pred_y)\n",
    "accuracy  = accuracy_score(test_y, pred_y)\n",
    "precision = precision_score(test_y, pred_y)\n",
    "recall    = recall_score(test_y, pred_y)\n",
    "\n",
    "# 지표를 통한 결과 확인\n",
    "print('================= confusion matrix ====================')\n",
    "print(confusion)\n",
    "print('=======================================================')\n",
    "print(f'정확도:{accuracy}, 정밀도:{precision}, 재현율:{recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ceb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# ROC curve 만들기\n",
    "fpr, tpr, thresholds = roc_curve(test_y, pred_y)\n",
    "auc = roc_auc_score(test_y, pred_y)\n",
    "\n",
    "# ROC curve 시각화\n",
    "plt.plot(fpr, tpr, linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "print(f'auc:{auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수를 선언한 기능이 LLM환경에만 존재하는 것으로 보임, 함수 몇개가 외부에서 호출이 안되며, LLM한경에만 존재함. \n",
    "# 이경우 OS EHsms sys를 활용해야 하는 것으로 보이나 아직은 지식이 부족함\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
